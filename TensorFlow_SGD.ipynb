{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflowを使った勾配降下法の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowを使い、勾配降下法を実装します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリのインポートを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 単純な一次方程式の解を勾配降下法で導く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規分布に従うランダムな0～1の値100個に対し、全ての解が10となるような計算式を考えます。\n",
    "\n",
    "$y = A \\times x$\n",
    "\n",
    "(y=10固定, xは0～1の値を取る)\n",
    "\n",
    "xは0～1の間を取るため、Aは一意には定まりませんが、 10 - y の値が最小となるようなAを勾配降下法から導きたいと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力値と正解データを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、正解の値を全て10とした100個の配列を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = np.repeat(10.,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それに対し、正規分布に従う0～1の範囲内のランダムな入力x_valを用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.random.normal(1,0.1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_vals, x_valsに対し、 $ Y = x \\times A$ とした変数$A$を用意し、$Y - y\\_vals$ の値が最小となるような$A$を求めるグラフをTensorFlowで作成します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要な変数、プレースホルダを用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(shape=[1, 1], dtype=tf.float32)\n",
    "print(x.shape)\n",
    "Y = tf.placeholder(shape=[1, 1], dtype=tf.float32)\n",
    "print(Y.shape)\n",
    "A = tf.Variable(tf.random.normal(shape=[1, 1]))\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問1 上記で使用したtf.Session, tf.placeholder, tf.Variableの意味をまとめてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Session : セッションを生成\n",
    "\n",
    "tf.plaeholder : 教師データを変数に格納する際に使用\n",
    "\n",
    "tf.Variable : 学習につかうパラメータの定義の際に使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問2 Tensorflowの関数を使い、x * A となる計算グラフを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.matmul(x, A) # x * A となる演算を作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問3 (x * A - Y)^2 を損失関数とし、損失を求める計算グラフを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(output - Y))  # (output - Y)^2 となる演算を作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セッションの初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問4 勾配降下法はTensorFlowのオプティマイザを使います。勾配降下法のオプティマイザを使用し、損失を最小にする計算グラフを作成してください（学習率は0.02とします）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.02)\n",
    "optimizer_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問5 学習を実行する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差を最小化する学習を行ってください。学習回数は10万回とし、10000ステップごとにAの値と損失を表示します。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b17e29a455b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrand_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrand_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrand_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "rand_x = np.zeros((1, 1))\n",
    "rand_y = np.zeros((1, 1))\n",
    "\n",
    "for i in range(100000):\n",
    "    rand_index = np.random.choice(100)\n",
    "    \n",
    "    rand_x[0, 0] = x_vals[rand_index]\n",
    "    rand_y[0, 0] = y_vals[rand_index]\n",
    "    \n",
    "    sess.run(optimizer_op, feed_dict={x:rand_x, Y:rand_y})\n",
    "    \n",
    "    if (i+1) % 10000 == 0:\n",
    "        print('Step #'+str(i+1)+\" A = \"+str(sess.run(A)))\n",
    "        print('Loss #'+str(i+1)+\" loss = \"+str(sess.run(loss, feed_dict={x:rand_x, Y:rand_y})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # まとめたもの\n",
    "# x_vals = np.random.normal(1,0.1,100)\n",
    "# y_vals = np.repeat(10.,100)\n",
    "# x = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "# Y = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "# A = tf.Variable(tf.random.normal(shape=[1]), name=\"A\")\n",
    "# output = x * A\n",
    "# loss = tf.reduce_mean(tf.square(output - Y), name=\"loss\")  \n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.02)\n",
    "# optimizer_op = optimizer.minimize(loss)\n",
    "\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     for i in range(100000):\n",
    "#         rand_index = np.random.choice(100)\n",
    "#         rand_x = [x_vals[rand_index]]\n",
    "#         rand_y = [y_vals[rand_index]]\n",
    "\n",
    "#         sess.run(optimizer_op,  feed_dict={x:rand_x, Y:rand_y})\n",
    "        \n",
    "#         if (i+1) % 10000 == 0:\n",
    "#             print('Step #'+str(i+1)+\" A = \"+str(sess.run(A)))\n",
    "#             print('Loss #'+str(i+1)+\" loss = \"+str(sess.run(loss, feed_dict={x:rand_x, Y:rand_y})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
